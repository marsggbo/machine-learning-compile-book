<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>2.4. TensorIR: 张量程序抽象案例研究 &#8212; 机器学习编译 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/mlc-favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2.5. TensorIR 练习" href="tensorir_exercises.html" />
    <link rel="prev" title="2.1. 元张量函数" href="tensor_program.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">2. </span>张量程序抽象</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">2.4. </span>TensorIR: 张量程序抽象案例研究</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_tensor_program/case_study.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://mlc.ai/summer22-zh">
                  <i class="fas fa-user-graduate"></i>
                  课程
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/mlc-ai/mlc-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://mlc.ai">
                  <i class="fas fa-external-link-alt"></i>
                  English
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/mlc-logo-with-text-landscape.svg" alt="机器学习编译"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 概述</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">2. 张量程序抽象</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tensor_program.html">2.1. 元张量函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_program.html#id2">2.2. 张量程序抽象</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_program.html#id4">2.3. 总结</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.4. TensorIR: 张量程序抽象案例研究</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorir_exercises.html">2.5. TensorIR 练习</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_end_to_end/index.html">3. 端到端模型执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_auto_program_optimization/index.html">4. 自动程序优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_integration/index.html">5. 与机器学习框架的整合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gpu_acceleration/index.html">6. GPU 硬件加速</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gpu_acceleration/part1.html">6.1. 第一部分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gpu_acceleration/part2.html">6.2. 第二部分</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_graph_optimization/index.html">7. 计算图优化</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/mlc-logo-with-text-landscape.svg" alt="机器学习编译"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 概述</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">2. 张量程序抽象</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tensor_program.html">2.1. 元张量函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_program.html#id2">2.2. 张量程序抽象</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_program.html#id4">2.3. 总结</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.4. TensorIR: 张量程序抽象案例研究</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorir_exercises.html">2.5. TensorIR 练习</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_end_to_end/index.html">3. 端到端模型执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_auto_program_optimization/index.html">4. 自动程序优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_integration/index.html">5. 与机器学习框架的整合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gpu_acceleration/index.html">6. GPU 硬件加速</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gpu_acceleration/part1.html">6.1. 第一部分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gpu_acceleration/part2.html">6.2. 第二部分</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_graph_optimization/index.html">7. 计算图优化</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="tensorir">
<h1><span class="section-number">2.4. </span>TensorIR: 张量程序抽象案例研究<a class="headerlink" href="#tensorir" title="Permalink to this heading">¶</a></h1>
<div class="section" id="id1">
<h2><span class="section-number">2.4.1. </span>安装相关的包<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<p>为了本课程的目标，我们会使用 TVM
（一个开源的机器学习编译框架）中一些正在持续开发的部分。我们提供了下面的命令用于为
MLC 课程安装一个包装好的版本。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w">  </span>pip<span class="w"> </span>install<span class="w"> </span>mlc-ai-nightly<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2><span class="section-number">2.4.2. </span>序言<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<div class="figure align-default">
<img alt="../_images/tensor_func_linear_relu.png" src="../_images/tensor_func_linear_relu.png" />
</div>
<p>在开始今天这一节之前，让我们回忆机器学习编译过程的关键原则。大多数的机器学习编译可以被视为张量函数之间的变换。在接下来的内容中我们主要想回答的以下几个问题：</p>
<ul class="simple">
<li><p>什么是表示张量函数可能的抽象？</p></li>
<li><p>什么是张量函数之间可能的变换？</p></li>
</ul>
<p>在这里我们将聚焦于元张量函数，部分讨论这些问题。</p>
</div>
<div class="section" id="id3">
<h2><span class="section-number">2.4.3. </span>学习一类张量程序抽象 – TensorIR<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h2>
<p>在之前的章节中，我们介绍过了元张量函数，讨论了张量程序抽象的总体概念。</p>
<p>现在我们已经准备好学习一个特定的张量程序抽象的实例：TensorIR。 TensorIR
是标准机器学习编译框架 Apache TVM 中使用的张量程序抽象。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm.ir.module</span> <span class="kn">import</span> <span class="n">IRModule</span>
<span class="kn">from</span> <span class="nn">tvm.script</span> <span class="kn">import</span> <span class="n">tir</span> <span class="k">as</span> <span class="n">T</span>
</pre></div>
</div>
<p>使用张量程序抽象的主要目的是表示循环和相关的硬件加速选择，如多线程、特殊硬件指令的使用和内存访问。</p>
<p>为了帮助我们更好地解释，我们用下面的张量计算作为示例。</p>
<p>具体地，对于两个大小为 <span class="math notranslate nohighlight">\(128 \times 128\)</span> 的矩阵 A 和
B，我们进行如下两步的张量计算。</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y_{i, j} = \sum_k A_{i, k} \times B_{k, j}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(C_{i, j} = \mathbb{relu}(Y_{i, j}) = \mathbb{max}(Y_{i, j}, 0)\)</span></p></li>
</ul>
<p>上面的计算很像在我们神经网络中经常看到的典型的元张量函数：一个线性层与一个
ReLU 激活层。首先，我们使用如下 NumPy 中的数组计算实现这两个操作。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>
<span class="n">a_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">b_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="c1"># a @ b is equivalent to np.matmul(a, b)</span>
<span class="n">c_mm_relu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">a_np</span> <span class="o">@</span> <span class="n">b_np</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>在底层，NumPy 调用库（例如 OpenBLAS）和它自己在低级 C
语言中的一些实现来执行这些计算。</p>
<p>从张量程序抽象的角度来看，我们想彻底理解这些数组计算的<strong>背后</strong>的细节。具体来说，我们想问：实现相应计算的可能方式是什么？</p>
<p>为了说明底层细节，我们将在 NumPy API 的一个受限子集中编写示例 ——
我们称之为 <strong>低级 NumPy</strong>。它使用以下的约定：</p>
<ul class="simple">
<li><p>我们将在必要时使用循环而不是数组函数来展示可能的循环计算。</p></li>
<li><p>如果可能，我们总是通过 <code class="docutils literal notranslate"><span class="pre">numpy.empty</span></code> 显式地分配数组并传递它们。</p></li>
</ul>
<p>需要注意的是，这不是人们通常编写 NumPy
程序的方式。不过，它们仍然与幕后发生的事情非常相似 ——
大多数现实世界的部署解决方案都将分配与计算分开处理。特定的库使用不同形式的循环和算术计算来执行计算。当然首先它们是使用诸如
<code class="docutils literal notranslate"><span class="pre">C</span></code> 之类的低级语言实现的。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lnumpy_mm_relu</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>上面的程序是实现 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code>
操作的一种方式。该程序包含两个阶段：首先我们分配一个中间存储
<span class="math notranslate nohighlight">\(Y\)</span>，将矩阵乘法的结果存储在那里。然后我们在第二个 for
循环序列中计算 ReLU。你可能会注意到，这肯定不是实现 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code>
的唯一方法，当然这可能也不是你想到的第一件事。</p>
<p>无论如何，这确实是实现 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code>
的方式之一。我们可以通过将我们的结果与使用数组计算的原始结果进行比较来验证代码的正确性。我们将在本节的后面部分回到这里，并重新讨论其他可能的方法。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">c_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">lnumpy_mm_relu</span><span class="p">(</span><span class="n">a_np</span><span class="p">,</span> <span class="n">b_np</span><span class="p">,</span> <span class="n">c_np</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_mm_relu</span><span class="p">,</span> <span class="n">c_np</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
<p>上面的示例代码展示了我们如何在<strong>幕后</strong>实现 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code>。当然，由于
Python 解释器，代码本身会运行得很慢。尽管如此，示例 NumPy
代码包含我们将在这些计算的实际实现中使用的所有可能元素。</p>
<ul class="simple">
<li><p>多维缓冲区（数组）。</p></li>
<li><p>在数组维度上的循环。</p></li>
<li><p>在循环下执行的计算语句。</p></li>
</ul>
<p>在看过低级 NumPy 示例后，现在我们准备介绍 TensorIR。下面的代码块展示了
<code class="docutils literal notranslate"><span class="pre">mm_relu</span></code> 的 TensorIR 实现。这里的代码是用一种名为 TVMScript
的语言实现的，它是一种嵌入在 Python AST 中的特定领域方言。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span> <span class="nc">MyModule</span><span class="p">:</span>
    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span> <span class="nf">mm_relu</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
                <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
                <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;mm_relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">):</span>
                <span class="n">vi</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
                <span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
                    <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vk</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
                <span class="n">vi</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
                <span class="n">C</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<p>能够同时查看 NumPy 代码和 TensorIR
代码并检查相应的元素是很有帮助的。我们将详细介绍它们。</p>
<div class="figure align-default">
<img alt="../_images/tensor_func_and_numpy.png" src="../_images/tensor_func_and_numpy.png" />
</div>
<p>我们首先回顾一下在 NumPy 和 TensorIR
之间具有直接对应关系的元素。接下来我们将回过来查看不属于 NumPy
程序的其他元素。</p>
<div class="section" id="id4">
<h3><span class="section-number">2.4.3.1. </span>函数参数与缓冲区<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>首先，让我们看一下函数参数。函数参数对应于 NumPy 函数上的同一组参数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TensorIR</span>
<span class="k">def</span> <span class="nf">mm_relu</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
            <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
            <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
    <span class="o">...</span>
<span class="c1"># numpy</span>
<span class="k">def</span> <span class="nf">lnumpy_mm_relu</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>这里 A、B 和 C 采用名为 <code class="docutils literal notranslate"><span class="pre">T.Buffer</span></code> 的类型，其形状参数为
<code class="docutils literal notranslate"><span class="pre">(128,</span> <span class="pre">128)</span></code>，数据类型为
<code class="docutils literal notranslate"><span class="pre">float32</span></code>。这些附加信息有助于可能的机器学习编译过程以生成专门针对形状和数据类型的代码。</p>
<p>同样，TensorIR 在中间结果分配中也使用了缓冲区类型。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TensorIR</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="c1"># numpy</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="for">
<h3><span class="section-number">2.4.3.2. </span>For 循环迭代<a class="headerlink" href="#for" title="Permalink to this heading">¶</a></h3>
<p>循环迭代也有直接对应关系。<code class="docutils literal notranslate"><span class="pre">T.grid</span></code> 是 TensorIR
中的语法糖，供我们书写多个嵌套的迭代器。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TensorIR</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
<span class="c1"># numpy</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3><span class="section-number">2.4.3.3. </span>计算块<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h3>
<p>主要区别之一来自计算语句。TensorIR 包含一个名为 <code class="docutils literal notranslate"><span class="pre">T.block</span></code> 的额外结构。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TensorIR</span>
<span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">):</span>
    <span class="n">vi</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
    <span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
        <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vk</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span>

<span class="c1"># coressponding numpy code</span>
<span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">,</span> <span class="n">vk</span> <span class="o">=</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span>
<span class="k">if</span> <span class="n">vk</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vk</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>块</strong> 是 TensorIR 中的基本计算单位。值得注意的是，该块包含比普通 NumPy
代码更多的信息。一个块包含一组块轴（<code class="docutils literal notranslate"><span class="pre">vi、vj、vk</span></code>）和围绕它们定义的计算。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vi</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
<span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
<span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>上面三行声明了关于块轴的<strong>关键性质</strong>，语法如下。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">block_axis</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="p">[</span><span class="n">axis_type</span><span class="p">]([</span><span class="n">axis_range</span><span class="p">],</span> <span class="p">[</span><span class="n">mapped_value</span><span class="p">])</span>
</pre></div>
</div>
<p>这三行包含以下信息：</p>
<ul class="simple">
<li><p>定义了 <code class="docutils literal notranslate"><span class="pre">vi</span></code>、<code class="docutils literal notranslate"><span class="pre">vj</span></code>、<code class="docutils literal notranslate"><span class="pre">vk</span></code> 应被绑定到的位置（在本例中为
<code class="docutils literal notranslate"><span class="pre">i</span></code>、<code class="docutils literal notranslate"><span class="pre">j</span></code> 和 <code class="docutils literal notranslate"><span class="pre">k</span></code>）；</p></li>
<li><p>声明了 <code class="docutils literal notranslate"><span class="pre">vi</span></code>、<code class="docutils literal notranslate"><span class="pre">vj</span></code>、<code class="docutils literal notranslate"><span class="pre">vk</span></code>
的原始范围（<code class="docutils literal notranslate"><span class="pre">T.axis.spatial(128,</span> <span class="pre">i)</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">128</span></code>）；</p></li>
<li><p>声明了块轴的属性（<code class="docutils literal notranslate"><span class="pre">spatial</span></code>, <code class="docutils literal notranslate"><span class="pre">reduce</span></code>）。</p></li>
</ul>
<p>我们一一浏览这些属性。首先，就边界关系而言，<code class="docutils literal notranslate"><span class="pre">vi</span> <span class="pre">=</span> <span class="pre">T.axis.spatial(128,</span> <span class="pre">i)</span></code>
有效地蕴含了 <code class="docutils literal notranslate"><span class="pre">vi</span> <span class="pre">=</span> <span class="pre">i</span></code>。<code class="docutils literal notranslate"><span class="pre">[axis_range]</span></code> 值提供了 <code class="docutils literal notranslate"><span class="pre">[block_axis]</span></code>
的预期范围。例如，<code class="docutils literal notranslate"><span class="pre">vi</span> <span class="pre">=</span> <span class="pre">T.axis.spatial(128,</span> <span class="pre">i)</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">128</span></code> 表明
<code class="docutils literal notranslate"><span class="pre">vi</span></code> 应该在 <code class="docutils literal notranslate"><span class="pre">range(0,</span> <span class="pre">128)</span></code> 中。</p>
</div>
<div class="section" id="id6">
<h3><span class="section-number">2.4.3.4. </span>块轴的属性<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<p>我们现在开始进一步研究块轴属性。这些轴属性标记了轴与正在执行的计算之间的关系。
下图总结了块（迭代）轴和块 <code class="docutils literal notranslate"><span class="pre">Y</span></code>
的读写关系。注意到，严格来说这个块正在对缓冲区 <code class="docutils literal notranslate"><span class="pre">Y</span></code>
进行（规约）更新，我们暂时将其标记为<em>写入</em>，因为我们不需要来自另一个块的缓冲区
<code class="docutils literal notranslate"><span class="pre">Y</span></code> 的值。</p>
<div class="figure align-default">
<img alt="../_images/tensor_ir_block_axis.png" src="../_images/tensor_ir_block_axis.png" />
</div>
<p>在我们的示例中，块 <code class="docutils literal notranslate"><span class="pre">Y</span></code> 通过读取来自 <code class="docutils literal notranslate"><span class="pre">A[vi,</span> <span class="pre">vk]</span></code> 和 <code class="docutils literal notranslate"><span class="pre">B[vk,</span> <span class="pre">vj]</span></code>
的值来计算结果 <code class="docutils literal notranslate"><span class="pre">Y[vi,</span> <span class="pre">vj]</span></code>，并对所有可能的 <code class="docutils literal notranslate"><span class="pre">vk</span></code> 执行求和。
在这个特定示例中，如果我们将 <code class="docutils literal notranslate"><span class="pre">vi</span></code>、<code class="docutils literal notranslate"><span class="pre">vj</span></code> 固定为
<code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1)</span></code>，并对 <code class="docutils literal notranslate"><span class="pre">vk</span> <span class="pre">in</span> <span class="pre">range(0,</span> <span class="pre">128)</span></code> 执行块
<code class="docutils literal notranslate"><span class="pre">Y</span></code>，我们可以独立于其他可能的位置（具有不同 <code class="docutils literal notranslate"><span class="pre">vi</span></code>, <code class="docutils literal notranslate"><span class="pre">vj</span></code>
值的位置）有效地计算 <code class="docutils literal notranslate"><span class="pre">C[0,</span> <span class="pre">1]</span></code>。</p>
<p>值得注意的是，对于一组固定的 <code class="docutils literal notranslate"><span class="pre">vi</span></code> 和 <code class="docutils literal notranslate"><span class="pre">vj</span></code>，计算块在 <code class="docutils literal notranslate"><span class="pre">Y</span></code>
的空间位置 (<code class="docutils literal notranslate"><span class="pre">Y[vi,</span> <span class="pre">vj]</span></code>) 处生成一个点值，该点值独立于 <code class="docutils literal notranslate"><span class="pre">Y</span></code>
中的其他位置（具有不同的<code class="docutils literal notranslate"><span class="pre">vi</span></code>, <code class="docutils literal notranslate"><span class="pre">vj</span></code> 值的位置）。我们可以称
<code class="docutils literal notranslate"><span class="pre">vi</span></code>、<code class="docutils literal notranslate"><span class="pre">vj</span></code>
为<strong>空间轴</strong>，因为它们直接对应于块写入的缓冲区空间区域的开始。
涉及归约的轴（<code class="docutils literal notranslate"><span class="pre">vk</span></code>）被命名为<strong>归约轴</strong>。</p>
</div>
<div class="section" id="id7">
<h3><span class="section-number">2.4.3.5. </span>为什么块需要额外附加的信息<a class="headerlink" href="#id7" title="Permalink to this heading">¶</a></h3>
<p>一个重要的观察结果是，附加信息（块轴范围及其属性）使块轴<strong>独立</strong>于外部循环嵌套
<code class="docutils literal notranslate"><span class="pre">i</span></code>, <code class="docutils literal notranslate"><span class="pre">j</span></code>, <code class="docutils literal notranslate"><span class="pre">k</span></code>。</p>
<p>块轴信息还提供了额外的属性，帮助我们验证用于执行计算的外部循环的正确性。例如，下面的代码块会导致错误，因为循环需要一个大小为
128 的迭代器，但我们只将它绑定到一个大小为 127 的 for 循环。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># wrong program due to loop and block iteration mismatch</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">127</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
        <span class="n">vi</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="o">^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>
        <span class="n">error</span> <span class="n">here</span> <span class="n">due</span> <span class="n">to</span> <span class="n">iterator</span> <span class="n">size</span> <span class="n">mismatch</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>这些附加信息也有助于我们进行机器学习编译分析。例如，虽然我们总是可以在空间轴上做并行化，在规约轴上进行并行化将需要特定的策略。</p>
</div>
<div class="section" id="id8">
<h3><span class="section-number">2.4.3.6. </span>块轴绑定的语法糖<a class="headerlink" href="#id8" title="Permalink to this heading">¶</a></h3>
<p>在每个块轴直接映射到外部循环迭代器的情况下，我们可以使用
<code class="docutils literal notranslate"><span class="pre">T.axis.remap</span></code> 在一行中声明所有块轴。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># SSR means the properties of each axes are &quot;spatial&quot;, &quot;spatial&quot;, &quot;reduce&quot;</span>
<span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">,</span> <span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
</pre></div>
</div>
<p>相当于</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vi</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="n">range_of_i</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
<span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">spatial</span><span class="p">(</span><span class="n">range_of_j</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
<span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">range_of_k</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>所以我们也可以编写如下程序。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span> <span class="nc">MyModuleWithAxisRemapSugar</span><span class="p">:</span>
    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span> <span class="nf">mm_relu</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
                <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
                <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;mm_relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">):</span>
                <span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">,</span> <span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
                    <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vk</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
                <span class="n">vi</span><span class="p">,</span> <span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SS&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">C</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h3><span class="section-number">2.4.3.7. </span>函数属性和装饰器<a class="headerlink" href="#id9" title="Permalink to this heading">¶</a></h3>
<p>到目前为止，我们已经涵盖了 TensorIR
中的大部分元素。在这一部分中，我们将介绍 TVMScript 的其余元素。</p>
<p>函数属性信息包含关于函数的额外信息。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;mm_relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</pre></div>
</div>
<p>这里的 <code class="docutils literal notranslate"><span class="pre">global_symbol</span></code> 对应函数名，<code class="docutils literal notranslate"><span class="pre">tir.noalias</span></code>
是一个属性，表示所有的缓冲存储器不重叠。你现在可以放心地跳过这些属性，因为它们不会影响对概念的整体理解。</p>
<p><code class="docutils literal notranslate"><span class="pre">&#64;tvm.script.ir_module</span></code> 和 <code class="docutils literal notranslate"><span class="pre">&#64;T.prim_func</span></code>
这两个装饰器用于表示对应部分的类型。</p>
<p><code class="docutils literal notranslate"><span class="pre">&#64;tvm.script.ir_module</span></code> 表示 <code class="docutils literal notranslate"><span class="pre">MyModule</span></code> 是一个 IRModule。IRModule
是在机器学习编译中保存张量函数集合的容器对象。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">MyModule</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">MyModule</span><span class="p">[</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>到目前为止，我们只看到包含单个张量函数的 IRModule。
机器学习编译过程中的一个 IRModule 可以包含多个张量函数。
以下代码块显示了具有两个函数的 IRModule 示例。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span> <span class="nc">MyModuleWithTwoFunctions</span><span class="p">:</span>
    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span> <span class="nf">mm</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
           <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
           <span class="n">Y</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;mm&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">):</span>
                <span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">,</span> <span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
                    <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vk</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span>

    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
             <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">)):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">):</span>
                <span class="n">vi</span><span class="p">,</span> <span class="n">vj</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SS&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">B</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="id10">
<h3><span class="section-number">2.4.3.8. </span>章节检查点<a class="headerlink" href="#id10" title="Permalink to this heading">¶</a></h3>
<p>到目前为止，我们一同看过了一个 TensorIR
程序示例，并涵盖了大部分元素，包括：</p>
<ul class="simple">
<li><p>参数和中间临时内存中的缓冲区声明；</p></li>
<li><p>For 循环迭代；</p></li>
<li><p><strong>块</strong>和块轴属性。</p></li>
</ul>
<p>在本节中，我们介绍了一个 TensorIR
示例，它涵盖了机器学习编译中最常见的元素。</p>
<p>TensorIR
包含的元素比我们在本节中介绍的更多，但本节涵盖了可以让我们开始机器学习编译之旅的大部分关键部分。我们将在后面的章节中介绍遇到的新元素。</p>
</div>
</div>
<div class="section" id="id11">
<h2><span class="section-number">2.4.4. </span>变换<a class="headerlink" href="#id11" title="Permalink to this heading">¶</a></h2>
<p>在上一节中，我们了解了 TensorIR 及其关键元素。
现在，让我们了解所有机器学习编译工作流的主要成分——元张量函数的变换。</p>
<p>在上一节中，我们给出了如何使用低级 NumPy 编写 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code> 的示例。
在实践中，可以有多种方法来实现相同的功能，并且每种实现都可能导致不同的性能。</p>
<p>我们将讨论性能背后的原因以及如何在以后的内容中利用这些变体。
在本节中，让我们关注使用变换获得不同实现变体的能力。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lnumpy_mm_relu_v2</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j0</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="n">j0</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">j1</span>
                    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">c_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">lnumpy_mm_relu_v2</span><span class="p">(</span><span class="n">a_np</span><span class="p">,</span> <span class="n">b_np</span><span class="p">,</span> <span class="n">c_np</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_mm_relu</span><span class="p">,</span> <span class="n">c_np</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
<p>上面的代码块显示了 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code>
的一个稍微不同的变体。它与原始程序的不同是</p>
<ul class="simple">
<li><p>我们用两个循环 <code class="docutils literal notranslate"><span class="pre">j0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">j1</span></code> 替换了 <code class="docutils literal notranslate"><span class="pre">j</span></code> 循环；</p></li>
<li><p>迭代顺序略有变化。</p></li>
</ul>
<p>为了获得
<code class="docutils literal notranslate"><span class="pre">lnumpy_mm_relu_v2</span></code>，我们必须重写一个新函数（或手动复制粘贴和编辑）。TensorIR
引入了一个名为 Schedule 的辅助结构，它允许我们务实地做到这一点。</p>
<p>为了提醒我们自己，让我们再看看当前的 <code class="docutils literal notranslate"><span class="pre">MyModule</span></code> 内容。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython</span>

<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">MyModule</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>现在我们准备好尝试代码变换。我们首先创建一个以给定的 <code class="docutils literal notranslate"><span class="pre">MyModule</span></code>
作为输入的 Schedule 辅助类。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">Schedule</span><span class="p">(</span><span class="n">MyModule</span><span class="p">)</span>
</pre></div>
</div>
<p>然后我们执行以下操作以获得对块 <code class="docutils literal notranslate"><span class="pre">Y</span></code> 和相应循环的引用。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">block_Y</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_block</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">func_name</span><span class="o">=</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">)</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_loops</span><span class="p">(</span><span class="n">block_Y</span><span class="p">)</span>
</pre></div>
</div>
<p>现在我们准备好进行变换了。我们将执行的第一个变换是将循环 <code class="docutils literal notranslate"><span class="pre">j</span></code>
分成两个循环，其中内部循环的长度为
4。请注意，变换是程序性的，因此如果你不小心执行了两次该代码块，我们将得到“变量
<code class="docutils literal notranslate"><span class="pre">j</span></code> 不再存在”的错误。如果发生这种情况，你可以从头（创建 <code class="docutils literal notranslate"><span class="pre">sch</span></code>
的位置）开始再次运行。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">j0</span><span class="p">,</span> <span class="n">j1</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">factors</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
<p>我们可以查看存储在 <code class="docutils literal notranslate"><span class="pre">sch.mod</span></code> 中的变换结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>在变换的第一步之后，我们创建了两个新的循环，<code class="docutils literal notranslate"><span class="pre">j_0</span></code> 和
<code class="docutils literal notranslate"><span class="pre">j_1</span></code>，分别对应范围 32 和 4。下一步是重新排序这两个循环。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">j0</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">j1</span><span class="p">)</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>现在重新排序后的代码非常类似于 <code class="docutils literal notranslate"><span class="pre">lnumpy_mm_relu_v2</span></code>。</p>
<div class="section" id="id12">
<h3><span class="section-number">2.4.4.1. </span>获得另一个变体<a class="headerlink" href="#id12" title="Permalink to this heading">¶</a></h3>
<p>在本节中，我们将继续进行另外两步变换以得到另一个变体。首先，我们使用名为
<code class="docutils literal notranslate"><span class="pre">reverse_compute_at</span></code> 的原语将块 <code class="docutils literal notranslate"><span class="pre">C</span></code> 移动到 <code class="docutils literal notranslate"><span class="pre">Y</span></code> 的内循环里。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">block_C</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_block</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;mm_relu&quot;</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">reverse_compute_at</span><span class="p">(</span><span class="n">block_C</span><span class="p">,</span> <span class="n">j0</span><span class="p">)</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>到目前为止，我们将归约初始化和更新放在一个块体中。这种组合形式为循环变换带来了便利（因为初始化和更新的外循环
<code class="docutils literal notranslate"><span class="pre">i</span></code>、<code class="docutils literal notranslate"><span class="pre">j</span></code> 通常需要彼此保持同步）。</p>
<p>在循环变换之后，我们可以将 <code class="docutils literal notranslate"><span class="pre">Y</span></code>
元素的初始化与归约更新分开。我们可以通过 <code class="docutils literal notranslate"><span class="pre">decompose_reduction</span></code>
原语来做到这一点。（注意：这也是 TVM
在以后编译的时候隐式做的，所以这一步的主要目的是让它显式，看看最终效果）。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span><span class="o">.</span><span class="n">decompose_reduction</span><span class="p">(</span><span class="n">block_Y</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>最终变换后的代码类似于以下低级 NumPy 代码。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lnumpy_mm_relu_v3</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j0</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="c1"># Y_init</span>
            <span class="k">for</span> <span class="n">j1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="n">j</span> <span class="o">=</span> <span class="n">j0</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">j1</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Y_update</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="n">j0</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">j1</span>
                    <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="c1"># C</span>
            <span class="k">for</span> <span class="n">j1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="n">j</span> <span class="o">=</span> <span class="n">j0</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">j1</span>
                <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">c_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">lnumpy_mm_relu_v3</span><span class="p">(</span><span class="n">a_np</span><span class="p">,</span> <span class="n">b_np</span><span class="p">,</span> <span class="n">c_np</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_mm_relu</span><span class="p">,</span> <span class="n">c_np</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id13">
<h3><span class="section-number">2.4.4.2. </span>章节总结与讨论<a class="headerlink" href="#id13" title="Permalink to this heading">¶</a></h3>
<p>本节的主要内容是习惯增量代码变换的范例。在我们的特定示例中，我们使用
<code class="docutils literal notranslate"><span class="pre">tir.Schedule</span></code> 作为辅助工具。</p>
<p>重要的是，我们避免了重新创建同一程序的不同变体（<code class="docutils literal notranslate"><span class="pre">lnumpy_mm_relu</span></code>、<code class="docutils literal notranslate"><span class="pre">lnumpy_mm_relu_v2</span></code>
和 <code class="docutils literal notranslate"><span class="pre">lnumpy_mm_relu_v3</span></code>）的需要。
块中的附加信息（轴信息）是我们可以在后台进行此类变换的原因。</p>
</div>
</div>
<div class="section" id="id14">
<h2><span class="section-number">2.4.5. </span>构建与运行<a class="headerlink" href="#id14" title="Permalink to this heading">¶</a></h2>
<p>到目前为止，我们只查看了变换结果的 TVMScript 输出。我们也可以运行
IRModule 中得到的程序。</p>
<p>首先，我们调用构建函数将 IRModule 变换为
<code class="docutils literal notranslate"><span class="pre">runtime.Module</span></code>，它表示可运行函数的集合。 这里 <code class="docutils literal notranslate"><span class="pre">target</span></code>
指定了部署环境的详细信息。对于现在这种特殊情况，我们将使用
<code class="docutils literal notranslate"><span class="pre">llvm</span></code>，它可以帮助我们编译到本机 CPU 平台。</p>
<p>当我们针对不同的平台（例如 Android 手机）或具有特殊说明的平台（Intel
Skylake）时，我们需要相应地调整
<code class="docutils literal notranslate"><span class="pre">target</span></code>。当我们开始部署到这些环境时，我们将讨论不同的目标选择。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rt_lib</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>然后，我们将创建三个用于保存输入和输出的 TVM NDArray。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a_nd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a_np</span><span class="p">)</span>
<span class="n">b_nd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b_np</span><span class="p">)</span>
<span class="n">c_nd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">c_nd</span><span class="p">)</span>
</pre></div>
</div>
<p>最后，我们可以从 <code class="docutils literal notranslate"><span class="pre">rt_lib</span></code>
中获取可运行函数，并通过传递三个数组参数来执行它。我们可以进一步运行验证来检查代码差异。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">func_mm_relu</span> <span class="o">=</span> <span class="n">rt_lib</span><span class="p">[</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">]</span>
<span class="n">func_mm_relu</span><span class="p">(</span><span class="n">a_nd</span><span class="p">,</span> <span class="n">b_nd</span><span class="p">,</span> <span class="n">c_nd</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_mm_relu</span><span class="p">,</span> <span class="n">c_nd</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
<p>我们已经构建并运行了原始的 <code class="docutils literal notranslate"><span class="pre">MyModule</span></code>。 我们还可以构建变换后的程序。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rt_lib_after</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="n">rt_lib_after</span><span class="p">[</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">](</span><span class="n">a_nd</span><span class="p">,</span> <span class="n">b_nd</span><span class="p">,</span> <span class="n">c_nd</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_mm_relu</span><span class="p">,</span> <span class="n">c_nd</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
<p>最后，我们可以比较一下两者的时间差。 <code class="docutils literal notranslate"><span class="pre">time_evaluator</span></code>
是一个辅助的测试函数，可用于比较不同生成函数的运行性能。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f_timer_before</span> <span class="o">=</span> <span class="n">rt_lib</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">,</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time cost of MyModule </span><span class="si">%g</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="n">f_timer_before</span><span class="p">(</span><span class="n">a_nd</span><span class="p">,</span> <span class="n">b_nd</span><span class="p">,</span> <span class="n">c_nd</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
<span class="n">f_timer_after</span> <span class="o">=</span> <span class="n">rt_lib_after</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">,</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time cost of transformed sch.mod </span><span class="si">%g</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="n">f_timer_after</span><span class="p">(</span><span class="n">a_nd</span><span class="p">,</span> <span class="n">b_nd</span><span class="p">,</span> <span class="n">c_nd</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
</pre></div>
</div>
<p>两个代码之间的运行时间差异很有意思。让我们快速分析一下影响性能的可能因素。
首先，让我们回忆原始代码的两种变体。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython</span>

<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">MyModule</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/cpu_arch.png" src="../_images/cpu_arch.png" />
</div>
<p>要了解为什么不同的循环变体会导致不同的性能，我们需要回顾一个事实，即访问
<code class="docutils literal notranslate"><span class="pre">A</span></code> 和 <code class="docutils literal notranslate"><span class="pre">B</span></code> 中的任何内存块的速度并不一致。现代 CPU
带有多级缓存，需要先将数据提取到缓存中，然后 CPU 才能访问它。</p>
<p>重要的是，访问已经在缓存中的数据要快得多。CPU
采用的一种策略是获取彼此更接近的数据。
当我们读取内存中的一个元素时，它会尝试将附近的元素（更正式的名称为“缓存行”）获取到缓存中。
因此，当你读取下一个元素时，它已经在缓存中。
因此，具有连续内存访问的代码通常比随机访问内存不同部分的代码更快。</p>
<div class="figure align-default">
<img alt="../_images/tensor_func_loop_order.png" src="../_images/tensor_func_loop_order.png" />
</div>
<p>现在让我们看看上面的迭代可视化，分析一下是怎么回事。
在这个分析中，让我们关注最里面的两个循环：<code class="docutils literal notranslate"><span class="pre">k</span></code> 和
<code class="docutils literal notranslate"><span class="pre">j1</span></code>。高亮的地方显示了当我们针对 <code class="docutils literal notranslate"><span class="pre">k</span></code> 的一个特定实例迭代 <code class="docutils literal notranslate"><span class="pre">j1</span></code>
时迭代触及的 <code class="docutils literal notranslate"><span class="pre">Y</span></code>、<code class="docutils literal notranslate"><span class="pre">A</span></code> 和 <code class="docutils literal notranslate"><span class="pre">B</span></code> 中的相应区域。</p>
<p>我们可以发现，<code class="docutils literal notranslate"><span class="pre">j1</span></code> 这一迭代产生了对 <code class="docutils literal notranslate"><span class="pre">B</span></code>
元素的<strong>连续访问</strong>。具体来说，它意味着在 <code class="docutils literal notranslate"><span class="pre">j1=0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">j1=1</span></code>
时我们读取的值彼此相邻。这可以让我们拥有更好的缓存访问行为。此外，我们使
<code class="docutils literal notranslate"><span class="pre">C</span></code> 的计算更接近 <code class="docutils literal notranslate"><span class="pre">Y</span></code>，从而实现更好的缓存行为。</p>
<p>我们当前的示例主要是为了证明不同的代码变体可以导致不同的性能。更多的变换步骤可以帮助我们获得更好的性能，我们将在以后的章节中介绍。本练习的主要目标是首先让我们获得程序变换工具，并首先体验通过变换可能实现的功能。</p>
<div class="section" id="id15">
<h3><span class="section-number">2.4.5.1. </span>练习<a class="headerlink" href="#id15" title="Permalink to this heading">¶</a></h3>
<p>作为练习，尝试不同的 <code class="docutils literal notranslate"><span class="pre">j_factor</span></code> 选择，看看它们如何影响代码的性能。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">jfactor</span><span class="p">):</span>
    <span class="n">sch</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">Schedule</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
    <span class="n">block_Y</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_block</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">func_name</span><span class="o">=</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">)</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_loops</span><span class="p">(</span><span class="n">block_Y</span><span class="p">)</span>
    <span class="n">j0</span><span class="p">,</span> <span class="n">j1</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">factors</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">jfactor</span><span class="p">])</span>
    <span class="n">sch</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">j0</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">j1</span><span class="p">)</span>
    <span class="n">block_C</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_block</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;mm_relu&quot;</span><span class="p">)</span>
    <span class="n">sch</span><span class="o">.</span><span class="n">reverse_compute_at</span><span class="p">(</span><span class="n">block_C</span><span class="p">,</span> <span class="n">j0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sch</span><span class="o">.</span><span class="n">mod</span>

<span class="n">mod_transformed</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="n">jfactor</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">rt_lib_transformed</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod_transformed</span><span class="p">,</span> <span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="n">f_timer_transformed</span> <span class="o">=</span> <span class="n">rt_lib_transformed</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">,</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time cost of transformed mod_transformed </span><span class="si">%g</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="n">f_timer_transformed</span><span class="p">(</span><span class="n">a_nd</span><span class="p">,</span> <span class="n">b_nd</span><span class="p">,</span> <span class="n">c_nd</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
<span class="c1"># display the code below</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">mod_transformed</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id16">
<h2><span class="section-number">2.4.6. </span>创建 TensorIR 并与之交互的方法<a class="headerlink" href="#id16" title="Permalink to this heading">¶</a></h2>
<p>在上面几节中，我们了解了 TensorIR 抽象和程序变换的方法。TensorIR
具有一个名为“块”的附加结构，可以帮助我们分析和执行代码变换。自然而然我们可能会问一个问题：创建
TensorIR 函数并与之交互的常用方法有什么？</p>
<div class="section" id="tvmscript-tensorir">
<h3><span class="section-number">2.4.6.1. </span>通过 TVMScript 创建 TensorIR<a class="headerlink" href="#tvmscript-tensorir" title="Permalink to this heading">¶</a></h3>
<p>获取 TensorIR 函数的第一种方法是直接在 TVMScript
中编写函数，这也是我们在上一节中使用的方法。 TVMScript
还允许我们在必要时跳过某些信息部分。 例如，<code class="docutils literal notranslate"><span class="pre">T.axis.remap</span></code>
使我们能够缩短迭代器大小注释。</p>
<p>TVMScript
也是一种在变换过程中检查张量函数的有用方法。在某些情况下，一种很有帮助的做法是打印出
TVMScript，进行一些手动编辑，然后将其反馈给机器学习编译流程以调试和尝试可能的（手动）变换，然后将变换后的程序重新应用到
MLC 流程中。</p>
</div>
<div class="section" id="id17">
<h3><span class="section-number">2.4.6.2. </span>使用张量表达式生成 TensorIR 代码<a class="headerlink" href="#id17" title="Permalink to this heading">¶</a></h3>
<p>在许多情况下，我们的开发形式是不在循环级别的更高级别的抽象。
所以另一种常见的获取 TensorIR 的方式是务实地生成相关代码。</p>
<p>张量表达式 (TE) 是一种特定领域的语言，它通过 API
之类的表达式描述一系列计算。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">te</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>这里 <code class="docutils literal notranslate"><span class="pre">te.compute</span></code> 采用签名 <code class="docutils literal notranslate"><span class="pre">te.compute(output_shape,</span> <span class="pre">fcompute)</span></code>。
<code class="docutils literal notranslate"><span class="pre">fcompute</span></code> 函数描述了对于给定的索引 <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> 我们要如何计算元素
<code class="docutils literal notranslate"><span class="pre">Y[i,</span> <span class="pre">j]</span></code> 的值。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>上面的 lambda 表达式描述了计算
<span class="math notranslate nohighlight">\(Y_{ij} = \sum_k A_{ik} B_{kj}\)</span>。在描述计算之后，我们可以通过传递我们感兴趣的相关参数来创建一个
TensorIR
函数。在这种特殊情况下，我们想要创建一个具有两个输入参数（<code class="docutils literal notranslate"><span class="pre">A</span></code>，<code class="docutils literal notranslate"><span class="pre">B</span></code>）和一个输出参数（<code class="docutils literal notranslate"><span class="pre">C</span></code>）的函数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">te_func</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">create_prim_func</span><span class="p">([</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">])</span><span class="o">.</span><span class="n">with_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;mm_relu&quot;</span><span class="p">})</span>
<span class="n">MyModuleFromTE</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">IRModule</span><span class="p">({</span><span class="s2">&quot;mm_relu&quot;</span><span class="p">:</span> <span class="n">te_func</span><span class="p">})</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Code</span><span class="p">(</span><span class="n">MyModuleFromTE</span><span class="o">.</span><span class="n">script</span><span class="p">(),</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>张量表达式 API 作为一个有用的工具，帮助为给定的更高级别的输入生成
TensorIR 函数。</p>
</div>
</div>
<div class="section" id="id18">
<h2><span class="section-number">2.4.7. </span>作为变换结果的 TensorIR 函数<a class="headerlink" href="#id18" title="Permalink to this heading">¶</a></h2>
<p>在实践中，我们还将 TensorIR 函数作为变换的结果。
当我们从两个元张量函数（<code class="docutils literal notranslate"><span class="pre">mm</span></code> 和
<code class="docutils literal notranslate"><span class="pre">relu</span></code>）开始，然后应用变换将它们“融合”成单个原始张量函数 <code class="docutils literal notranslate"><span class="pre">mm_relu</span></code>
时，就会发生这种情况。我们将在以后的章节中介绍详细信息。</p>
</div>
<div class="section" id="id19">
<h2><span class="section-number">2.4.8. </span>讨论<a class="headerlink" href="#id19" title="Permalink to this heading">¶</a></h2>
<p>在本节中，让我们回顾一下到目前为止我们学到了什么。我们了解到，一个常见的机器学习编译过程遵循一系列程序变换。将
TensorIR 变换过程与低级 NumPy 参考开发过程进行比较是很有趣的。</p>
<div class="figure align-default">
<img alt="../_images/standard_process.png" src="../_images/standard_process.png" />
</div>
<p>上图显示了标准的开发过程。我们需要重复开发不同程序变体的过程，然后（如果它是编译语言，则构建）在感兴趣的平台上运行它们。</p>
<p>机器学习编译流程（如下图所示）的主要区别在于
IRModule（程序）之间的程序变换。所以我们不仅可以通过开发（通过手动编写代码或生成代码）提出程序变体，还可以通过变换张量程序来获得变体。</p>
<p>变换是一个非常强大的工具，可以帮助我们简化开发成本并为流程引入更多自动化。本节介绍了通过
TensorIR 对元张量函数的特定视角，我们将在未来涵盖更多视角。</p>
<div class="figure align-default">
<img alt="../_images/mlc_process.png" src="../_images/mlc_process.png" />
</div>
<p>值得注意的是，直接代码开发和变换在实践中同样重要：我们仍然可以利用大量领域专业知识来开发和优化部分程序，然后将其与基于变换的方法相结合。我们将在以后的章节中讨论如何将这两种实践结合起来。</p>
</div>
<div class="section" id="id20">
<h2><span class="section-number">2.4.9. </span>总结<a class="headerlink" href="#id20" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>TensorIR 抽象</p>
<ul>
<li><p>包含循环、多维缓冲区等常用元素</p></li>
<li><p>引入了一个封装循环计算要求的新结构<strong>块</strong>。</p></li>
<li><p>可以在 Python AST 中构建（通过 TVMScript）</p></li>
</ul>
</li>
<li><p>我们可以使用变换来创建不同的 TensorIR 变体。</p></li>
<li><p>通用 MLC 流程：开发、变换、构建。</p></li>
</ul>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">2.4. TensorIR: 张量程序抽象案例研究</a><ul>
<li><a class="reference internal" href="#id1">2.4.1. 安装相关的包</a></li>
<li><a class="reference internal" href="#id2">2.4.2. 序言</a></li>
<li><a class="reference internal" href="#id3">2.4.3. 学习一类张量程序抽象 – TensorIR</a><ul>
<li><a class="reference internal" href="#id4">2.4.3.1. 函数参数与缓冲区</a></li>
<li><a class="reference internal" href="#for">2.4.3.2. For 循环迭代</a></li>
<li><a class="reference internal" href="#id5">2.4.3.3. 计算块</a></li>
<li><a class="reference internal" href="#id6">2.4.3.4. 块轴的属性</a></li>
<li><a class="reference internal" href="#id7">2.4.3.5. 为什么块需要额外附加的信息</a></li>
<li><a class="reference internal" href="#id8">2.4.3.6. 块轴绑定的语法糖</a></li>
<li><a class="reference internal" href="#id9">2.4.3.7. 函数属性和装饰器</a></li>
<li><a class="reference internal" href="#id10">2.4.3.8. 章节检查点</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id11">2.4.4. 变换</a><ul>
<li><a class="reference internal" href="#id12">2.4.4.1. 获得另一个变体</a></li>
<li><a class="reference internal" href="#id13">2.4.4.2. 章节总结与讨论</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id14">2.4.5. 构建与运行</a><ul>
<li><a class="reference internal" href="#id15">2.4.5.1. 练习</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id16">2.4.6. 创建 TensorIR 并与之交互的方法</a><ul>
<li><a class="reference internal" href="#tvmscript-tensorir">2.4.6.1. 通过 TVMScript 创建 TensorIR</a></li>
<li><a class="reference internal" href="#id17">2.4.6.2. 使用张量表达式生成 TensorIR 代码</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id18">2.4.7. 作为变换结果的 TensorIR 函数</a></li>
<li><a class="reference internal" href="#id19">2.4.8. 讨论</a></li>
<li><a class="reference internal" href="#id20">2.4.9. 总结</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="tensor_program.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>2.1. 元张量函数</div>
         </div>
     </a>
     <a id="button-next" href="tensorir_exercises.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>2.5. TensorIR 练习</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>