<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>6.2. 第二部分 &#8212; 机器学习编译 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <link rel="shortcut icon" href="../_static/mlc-favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. 计算图优化" href="../chapter_graph_optimization/index.html" />
    <link rel="prev" title="6.1. 第一部分" href="part1.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">6. </span>GPU 硬件加速</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">6.2. </span>第二部分</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_gpu_acceleration/part2.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://mlc.ai/summer22-zh">
                  <i class="fas fa-user-graduate"></i>
                  课程
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/mlc-ai/mlc-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://mlc.ai">
                  <i class="fas fa-external-link-alt"></i>
                  English
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/mlc-logo-with-text-landscape.svg" alt="机器学习编译"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_tensor_program/index.html">2. 张量程序抽象</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensor_program.html">2.1. 元张量函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensor_program.html#id2">2.2. 张量程序抽象</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensor_program.html#id4">2.3. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/case_study.html">2.4. TensorIR: 张量程序抽象案例研究</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensorir_exercises.html">2.5. TensorIR 练习</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_end_to_end/index.html">3. 端到端模型执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_auto_program_optimization/index.html">4. 自动程序优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_integration/index.html">5. 与机器学习框架的整合</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">6. GPU 硬件加速</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="part1.html">6.1. 第一部分</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">6.2. 第二部分</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_graph_optimization/index.html">7. 计算图优化</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/mlc-logo-with-text-landscape.svg" alt="机器学习编译"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_tensor_program/index.html">2. 张量程序抽象</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensor_program.html">2.1. 元张量函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensor_program.html#id2">2.2. 张量程序抽象</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensor_program.html#id4">2.3. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/case_study.html">2.4. TensorIR: 张量程序抽象案例研究</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_tensor_program/tensorir_exercises.html">2.5. TensorIR 练习</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_end_to_end/index.html">3. 端到端模型执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_auto_program_optimization/index.html">4. 自动程序优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_integration/index.html">5. 与机器学习框架的整合</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">6. GPU 硬件加速</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="part1.html">6.1. 第一部分</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">6.2. 第二部分</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_graph_optimization/index.html">7. 计算图优化</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="id1">
<h1><span class="section-number">6.2. </span>第二部分<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<p>我们在过去的章节中讨论了为 CPU 和 GPU
环境构建机器学习编译流程。本节重点介绍我们如何为专门的硬件后端构建概念编程模型。</p>
<div class="section" id="id2">
<h2><span class="section-number">6.2.1. </span>准备工作<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<p>首先，让我们导入必要的依赖项。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relax</span>
<span class="kn">from</span> <span class="nn">tvm.ir.module</span> <span class="kn">import</span> <span class="n">IRModule</span>
<span class="kn">from</span> <span class="nn">tvm.script</span> <span class="kn">import</span> <span class="n">relax</span> <span class="k">as</span> <span class="n">R</span>
<span class="kn">from</span> <span class="nn">tvm.script</span> <span class="kn">import</span> <span class="n">tir</span> <span class="k">as</span> <span class="n">T</span>
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h2><span class="section-number">6.2.2. </span>硬件专业化趋势<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h2>
<div class="figure align-default">
<img alt="../_images/hardware_specialization.png" src="../_images/hardware_specialization.png" />
</div>
<p>如果我们看看机器学习硬件领域，可以发现最近一个新兴的主题是专业化。传统上，我们在通用标量处理器上构建我们的解决方案：我们可以一次在一个浮点上执行操作。AVX
和 ARM/Neon
等向量指令集提供了加速程序的有效方法，但也给我们编写程序的方式带来了一些复杂性。</p>
<p>最新的机器学习加速器引入了用于张量计算的专用单元，以及用于多维数据复制和矩阵/张量计算的指令。</p>
<div class="section" id="id4">
<h3><span class="section-number">6.2.2.1. </span>专业化代码中的关键要素<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>为了帮助我们更好地理解专业硬件编程的元素，让我们首先研究以下 <strong>low-level
NumPy</strong> 代码。 虽然这段代码仍然在 Python
中运行，但它类似于一组可能发生在专用硬件后端的操作。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accel_fill_zero</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
    <span class="n">C</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">accel_tmm_add</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
    <span class="n">C</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">B</span><span class="o">.</span><span class="n">T</span>

<span class="k">def</span> <span class="nf">accel_dma_copy</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="n">dram</span><span class="p">):</span>
    <span class="n">reg</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">dram</span><span class="p">[:]</span>

<span class="k">def</span> <span class="nf">lnumpy_tmm</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="c1"># a special accumulator memory</span>
    <span class="n">C_accumulator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">A_reg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">B_reg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
            <span class="n">accel_fill_zero</span><span class="p">(</span><span class="n">C_accumulator</span><span class="p">[:,:])</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
                <span class="n">accel_dma_copy</span><span class="p">(</span><span class="n">A_reg</span><span class="p">[:],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">k</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">])</span>
                <span class="n">accel_dma_copy</span><span class="p">(</span><span class="n">B_reg</span><span class="p">[:],</span> <span class="n">B</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">k</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">])</span>
                <span class="n">accel_tmm_add</span><span class="p">(</span><span class="n">C_accumulator</span><span class="p">[:,:],</span> <span class="n">A_reg</span><span class="p">,</span> <span class="n">B_reg</span><span class="p">)</span>
            <span class="n">accel_dma_copy</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">],</span> <span class="n">C_accumulator</span><span class="p">[:,:])</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/hardware_specialization_abc.png" src="../_images/hardware_specialization_abc.png" />
</div>
<p>上面的低级 NumPy 程序包含以下关键元素：</p>
<ul class="simple">
<li><p>计算的基本单位是 16x16x16 矩阵乘法 (<code class="docutils literal notranslate"><span class="pre">accel_tmm_add</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">accel_tmm_add</span></code> 接受两个输入 —— <code class="docutils literal notranslate"><span class="pre">A_reg</span></code> 和 <code class="docutils literal notranslate"><span class="pre">B_reg</span></code>
并累加到累加器内存中。</p></li>
<li><p>使用特殊功能 (<code class="docutils literal notranslate"><span class="pre">accel_dma_copy</span></code>) 执行数据复制。</p></li>
</ul>
<p>在现实世界的硬件后端中，我们通常期望 <code class="docutils literal notranslate"><span class="pre">A_reg</span></code>、<code class="docutils literal notranslate"><span class="pre">B_reg</span></code> 和
<code class="docutils literal notranslate"><span class="pre">C_accumulator</span></code>
映射到硬件中的特殊内存区域（或寄存器）。这些被称为<strong>特殊内存层级</strong>。
此外，我们可以对这些设置执行一组有限的硬件加速操作。 诸如
<code class="docutils literal notranslate"><span class="pre">accel_tmm_add</span></code>
之类的操作可以映射到真正的硬件指令或供应商提供的高效内核函数实现。</p>
<p>我们可以运行以下代码块来确认低级 NumPy 代码是否正确运行。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>
<span class="n">a_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">b_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">c_tmm</span> <span class="o">=</span> <span class="n">a_np</span> <span class="o">@</span> <span class="n">b_np</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">c_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">lnumpy_tmm</span><span class="p">(</span><span class="n">a_np</span><span class="p">,</span> <span class="n">b_np</span><span class="p">,</span> <span class="n">c_np</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_np</span><span class="p">,</span> <span class="n">c_tmm</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="block">
<h3><span class="section-number">6.2.2.2. </span>带有张量化计算的 block<a class="headerlink" href="#block" title="Permalink to this heading">¶</a></h3>
<p>我们的主要观察之一是专用加速器代码不是以标量计算为单位构建的。到目前为止，我们运行的大多数
TensorIR 代码都包含一个
block，用于计算输出张量中的单个元素。许多专门的加速器在张量区域上运行计算。
TensorIR 中的 block 结构帮助我们对此类相关计算进行分组。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span> <span class="nc">MatmulBlockModule</span><span class="p">:</span>
    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span>
        <span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;main&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">i0</span><span class="p">,</span> <span class="n">j0</span><span class="p">,</span> <span class="n">k0</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;tmm-16x16&quot;</span><span class="p">):</span>
                <span class="n">vi0</span><span class="p">,</span> <span class="n">vj0</span><span class="p">,</span> <span class="n">vk0</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">j0</span><span class="p">,</span> <span class="n">k0</span><span class="p">])</span>
                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">i1</span><span class="p">,</span> <span class="n">j1</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">):</span>
                        <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;tmm_init&quot;</span><span class="p">):</span>
                            <span class="n">vi1</span><span class="p">,</span> <span class="n">vj1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SS&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i1</span><span class="p">,</span> <span class="n">j1</span><span class="p">])</span>
                            <span class="n">C</span><span class="p">[</span><span class="n">vi0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vi1</span><span class="p">,</span> <span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vj1</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i1</span><span class="p">,</span> <span class="n">j1</span><span class="p">,</span> <span class="n">k1</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;tmm&quot;</span><span class="p">):</span>
                        <span class="n">vi1</span><span class="p">,</span> <span class="n">vj1</span><span class="p">,</span> <span class="n">vk1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i1</span><span class="p">,</span> <span class="n">j1</span><span class="p">,</span> <span class="n">k1</span><span class="p">])</span>
                        <span class="n">C</span><span class="p">[</span><span class="n">vi0</span> <span class="o">*</span><span class="mi">16</span> <span class="o">+</span> <span class="n">vi1</span><span class="p">,</span> <span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vj1</span><span class="p">]</span> <span class="o">+=</span> \
                            <span class="n">A</span><span class="p">[</span><span class="n">vi0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vi1</span><span class="p">,</span> <span class="n">vk0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vk1</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vj1</span><span class="p">,</span> <span class="n">vk0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">vk1</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MatmulBlockModule</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>我们进一步观察下面这个 block：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;tmm-16x16&quot;</span><span class="p">):</span>
    <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">vi0</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">vi0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">,</span> <span class="n">vk0</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">vk0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">,</span> <span class="n">vk0</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">vk0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">])</span>
    <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">vi0</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">vi0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">,</span> <span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="p">:</span> <span class="n">vj0</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="mi">16</span><span class="p">])</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>这个 block 从 <code class="docutils literal notranslate"><span class="pre">A</span></code> 和 <code class="docutils literal notranslate"><span class="pre">B</span></code> 的 16x16 区域读取，并写入 <code class="docutils literal notranslate"><span class="pre">C</span></code> 的 16x16
区域。 在这种情况下，block
的内容包含有关子区域计算的特定实现的更多细节。 我们将此 block
称为<strong>张量化 block</strong>，因为它们包含跨越张量子区域的计算。</p>
<p>我们可以运行以下代码来确认 TensorIR 模块产生了正确的结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a_nd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a_np</span><span class="p">)</span>
<span class="n">b_nd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b_np</span><span class="p">)</span>

<span class="n">c_nd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="n">lib</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">MatmulBlockModule</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="n">lib</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">](</span><span class="n">a_nd</span><span class="p">,</span> <span class="n">b_nd</span><span class="p">,</span> <span class="n">c_nd</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_nd</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">c_tmm</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3><span class="section-number">6.2.2.3. </span>变换在张量化 block 周围的循环<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h3>
<p>我们在这里可以做的一件事是变换张量计算 block
周围的循环。这些循环变换可以帮助我们重新组织周围的迭代方式，从而使得不同张量程序变体成为可能。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">Schedule</span><span class="p">(</span><span class="n">MatmulBlockModule</span><span class="p">)</span>

<span class="n">block_mm</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_block</span><span class="p">(</span><span class="s2">&quot;tmm-16x16&quot;</span><span class="p">)</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_loops</span><span class="p">(</span><span class="n">block_mm</span><span class="p">)</span>

<span class="n">i0</span><span class="p">,</span> <span class="n">i1</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

<span class="n">sch</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">i0</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">i1</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="blockization-block">
<h3><span class="section-number">6.2.2.4. </span>Blockization – 创造新的 block<a class="headerlink" href="#blockization-block" title="Permalink to this heading">¶</a></h3>
<p>在大多数情况下，我们从带有标量计算的循环开始。 TensorIR
提供了一种变换原语 blockization
来将循环的子区域组合在一起以形成张量化的计算 block。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tvm</span><span class="o">.</span><span class="n">script</span><span class="o">.</span><span class="n">ir_module</span>
<span class="k">class</span> <span class="nc">MatmulModule</span><span class="p">:</span>
    <span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span>
        <span class="n">A</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
        <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&quot;global_symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;main&quot;</span><span class="p">,</span> <span class="s2">&quot;tir.noalias&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;matmul&quot;</span><span class="p">):</span>
                <span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">,</span> <span class="n">vk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
                    <span class="n">C</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">C</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vj</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">vi</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vj</span><span class="p">,</span> <span class="n">vk</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">Schedule</span><span class="p">(</span><span class="n">MatmulModule</span><span class="p">)</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">get_loops</span><span class="p">(</span><span class="s2">&quot;matmul&quot;</span><span class="p">)</span>
<span class="n">i</span><span class="p">,</span> <span class="n">ii</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">factors</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="n">j</span><span class="p">,</span> <span class="n">ji</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">factors</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="n">k</span><span class="p">,</span> <span class="n">ki</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">factors</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="n">sch</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ii</span><span class="p">,</span> <span class="n">ji</span><span class="p">,</span> <span class="n">ki</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">block_mm</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">blockize</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="tensorir">
<h3><span class="section-number">6.2.2.5. </span>变换 TensorIR 以引入特殊内存层级<a class="headerlink" href="#tensorir" title="Permalink to this heading">¶</a></h3>
<p>正如我们在低级 NumPy 代码中所指出的，之前低级 TensorIR
的一个关键元素是加速期间使用的特殊内存层级。</p>
<p>我们可以使用 <code class="docutils literal notranslate"><span class="pre">cache_read</span></code> 和 <code class="docutils literal notranslate"><span class="pre">cache_write</span></code> 来创建中间内存阶段。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A_reg</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">cache_read</span><span class="p">(</span><span class="n">block_mm</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">storage_scope</span><span class="o">=</span><span class="s2">&quot;global.A_reg&quot;</span><span class="p">)</span>
<span class="n">B_reg</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">cache_read</span><span class="p">(</span><span class="n">block_mm</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">storage_scope</span><span class="o">=</span><span class="s2">&quot;global.B_reg&quot;</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">compute_at</span><span class="p">(</span><span class="n">A_reg</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">compute_at</span><span class="p">(</span><span class="n">B_reg</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

<span class="n">write_back_block</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">cache_write</span><span class="p">(</span><span class="n">block_mm</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">storage_scope</span><span class="o">=</span><span class="s2">&quot;global.accumulator&quot;</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">reverse_compute_at</span><span class="p">(</span><span class="n">write_back_block</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/hardware_specialization_abc.png" src="../_images/hardware_specialization_abc.png" />
</div>
<p>这里 <code class="docutils literal notranslate"><span class="pre">global.A_reg</span></code> 包含两个部分。 <code class="docutils literal notranslate"><span class="pre">global</span></code>
表示所有线程都可以全局访问内存，而 <code class="docutils literal notranslate"><span class="pre">A_reg</span></code>
是内存的<strong>层级标签</strong>，为后续编译映射到寄存器等特殊区域提供了机会。</p>
</div>
</div>
<div class="section" id="id6">
<h2><span class="section-number">6.2.3. </span>张量化<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h2>
<p>现在我们已经创建了一组映射到 TensorIR 中相应计算阶段的 block。
剩下的步骤是映射一些 block 以使用映射到硬件加速指令的特定实现。
此映射过程称为<strong>张量化</strong>。</p>
<p>为了准备张量化，我们首先注册一个张量
intrinsic（TensorIntrin），其中包含计算和实现的描述。</p>
<p>系统将使用描述找到与计算匹配的相关区域，而实现将计算映射到加速硬件指令。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
<span class="k">def</span> <span class="nf">tmm16_desc</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">handle</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">handle</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">handle</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">match_buffer</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">offset_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;global.A_reg&quot;</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">match_buffer</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">offset_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;global.B_reg&quot;</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">match_buffer</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">offset_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;global.accumulator&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;root&quot;</span><span class="p">):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">])</span>
        <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
                <span class="n">vii</span><span class="p">,</span> <span class="n">vjj</span><span class="p">,</span> <span class="n">vkk</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&quot;SSR&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
                <span class="n">C</span><span class="p">[</span><span class="n">vii</span><span class="p">,</span> <span class="n">vjj</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">vii</span><span class="p">,</span> <span class="n">vjj</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">vii</span><span class="p">,</span> <span class="n">vkk</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">vjj</span><span class="p">,</span> <span class="n">vkk</span><span class="p">]</span>


<span class="nd">@T</span><span class="o">.</span><span class="n">prim_func</span>
<span class="k">def</span> <span class="nf">tmm16_impl</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">handle</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">handle</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">handle</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">sa</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">int32</span><span class="p">()</span>
    <span class="n">sb</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">int32</span><span class="p">()</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">int32</span><span class="p">()</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">match_buffer</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">offset_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="n">sa</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;global.A_reg&quot;</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">match_buffer</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">offset_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="n">sb</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;global.B_reg&quot;</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">match_buffer</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">offset_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="n">sc</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;global.accumulator&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&quot;root&quot;</span><span class="p">):</span>
        <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">])</span>
        <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">])</span>
        <span class="n">T</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
            <span class="n">T</span><span class="o">.</span><span class="n">call_extern</span><span class="p">(</span>
                <span class="s2">&quot;tmm16&quot;</span><span class="p">,</span>
                <span class="n">C</span><span class="o">.</span><span class="n">access_ptr</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">),</span>
                <span class="n">A</span><span class="o">.</span><span class="n">access_ptr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">),</span>
                <span class="n">B</span><span class="o">.</span><span class="n">access_ptr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">),</span>
                <span class="n">sa</span><span class="p">,</span>
                <span class="n">sb</span><span class="p">,</span>
                <span class="n">sc</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

<span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">TensorIntrin</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;tmm16&quot;</span><span class="p">,</span> <span class="n">tmm16_desc</span><span class="p">,</span> <span class="n">tmm16_impl</span><span class="p">)</span>
</pre></div>
</div>
<p>作为准备步骤，我们首先将归约分解为一个初始化 block 和一个更新 block。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span><span class="o">.</span><span class="n">decompose_reduction</span><span class="p">(</span><span class="n">block_mm</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>然后我们可以调用 <code class="docutils literal notranslate"><span class="pre">tensorize</span></code>，将 <code class="docutils literal notranslate"><span class="pre">block_mm</span></code>（对应于
<code class="docutils literal notranslate"><span class="pre">matmul_o_update</span></code> block）映射到使用 <code class="docutils literal notranslate"><span class="pre">tmm16</span></code> 的实现。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span><span class="o">.</span><span class="n">tensorize</span><span class="p">(</span><span class="n">block_mm</span><span class="p">,</span> <span class="s2">&quot;tmm16&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sch</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>这里我们使用 <code class="docutils literal notranslate"><span class="pre">T.call_extern</span></code> 来调用环境中的外部函数。
下游编译步骤可以轻松地将实现映射到实现操作的指令。</p>
<p>或者，我们可以将 <code class="docutils literal notranslate"><span class="pre">tmm16</span></code> 映射到实现这种张量化计算的微内核。
以下代码显示了如何通过外部 C
代码执行此操作（如果需要，可以进一步嵌入内联汇编）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tmm_kernel</span><span class="p">():</span>
    <span class="n">cc_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">      extern &quot;C&quot; int tmm16(float *cc, float *aa, float *bb, int stride_a, int stride_b, int stride_c) {</span>
<span class="s2">        for (int i = 0; i &lt; 16; ++i) {</span>
<span class="s2">            for (int j = 0; j &lt; 16; ++j) {</span>
<span class="s2">                for (int k = 0; k &lt; 16; ++k) {</span>
<span class="s2">                    cc[i * stride_c + j] += aa[i * stride_a + k] * bb[j * stride_b + k];</span>
<span class="s2">                }</span>
<span class="s2">            }</span>
<span class="s2">        }</span>
<span class="s2">        return 0;</span>
<span class="s2">      }</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">clang</span><span class="p">,</span> <span class="n">utils</span>

    <span class="n">temp</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">tempdir</span><span class="p">()</span>
    <span class="n">ll_path</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="s2">&quot;temp.ll&quot;</span><span class="p">)</span>
    <span class="c1"># Create LLVM ir from c source code</span>
    <span class="n">ll_code</span> <span class="o">=</span> <span class="n">clang</span><span class="o">.</span><span class="n">create_llvm</span><span class="p">(</span><span class="n">cc_code</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">ll_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ll_code</span>

<span class="n">sch</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;pragma_import_llvm&quot;</span><span class="p">,</span> <span class="n">tmm_kernel</span><span class="p">())</span>
</pre></div>
</div>
<p>然后我们可以去执行下面的代码块，它将张量化的计算重定向到自定义的
<code class="docutils literal notranslate"><span class="pre">tmm_kernel</span></code>。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;!-- todo --&gt;
&lt;!-- For CI, do not run this part of the code --&gt;
a_nd = tvm.nd.array(a_np)
b_nd = tvm.nd.array(b_np)

c_nd = tvm.nd.empty((1024, 1024), dtype=&quot;float32&quot;)

lib = tvm.build(sch.mod, target=&quot;llvm&quot;)
lib[&quot;main&quot;](a_nd, b_nd, c_nd)
np.testing.assert_allclose(c_nd.numpy(), c_tmm, rtol=1e-5)
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h2><span class="section-number">6.2.4. </span>讨论<a class="headerlink" href="#id7" title="Permalink to this heading">¶</a></h2>
<p>本节介绍了一组专用硬件支持的关键元素。 这里的关键结构之一是张量化 block
和计算以及张量子区域。 TensorIR 还包含建立在基础元素之上的其他属性：</p>
<ul class="simple">
<li><p>专用内存中的布局约束。</p></li>
<li><p>与线程层次结构的交互。</p></li>
</ul>
<p>我们没有足够的时间在一次讲座中涵盖这些内容，但我们将在一些附加内容上添加可选读物。</p>
</div>
<div class="section" id="id8">
<h2><span class="section-number">6.2.5. </span>小结<a class="headerlink" href="#id8" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>硬件专业化向张量计算的总体趋势。</p></li>
<li><p>带有张量化 block 的 TensorIR 变换。</p></li>
<li><p>张量化：将循环计算 block 映射到专门实现的过程。</p></li>
</ul>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">6.2. 第二部分</a><ul>
<li><a class="reference internal" href="#id2">6.2.1. 准备工作</a></li>
<li><a class="reference internal" href="#id3">6.2.2. 硬件专业化趋势</a><ul>
<li><a class="reference internal" href="#id4">6.2.2.1. 专业化代码中的关键要素</a></li>
<li><a class="reference internal" href="#block">6.2.2.2. 带有张量化计算的 block</a></li>
<li><a class="reference internal" href="#id5">6.2.2.3. 变换在张量化 block 周围的循环</a></li>
<li><a class="reference internal" href="#blockization-block">6.2.2.4. Blockization – 创造新的 block</a></li>
<li><a class="reference internal" href="#tensorir">6.2.2.5. 变换 TensorIR 以引入特殊内存层级</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">6.2.3. 张量化</a></li>
<li><a class="reference internal" href="#id7">6.2.4. 讨论</a></li>
<li><a class="reference internal" href="#id8">6.2.5. 小结</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="part1.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>6.1. 第一部分</div>
         </div>
     </a>
     <a id="button-next" href="../chapter_graph_optimization/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>7. 计算图优化</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>